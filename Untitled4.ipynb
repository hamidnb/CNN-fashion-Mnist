{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1ajxBrTeUMqX"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "fashion_mnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "fashion_mnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(fashion_mnist_train, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(fashion_mnist_test, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMzPRsLOUQ0k",
        "outputId": "c8335db9-3909-4015-e4e6-c257aab83ac8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 170kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.24MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 15.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d((1, 1)),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "o_ofDlCAUSRZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 77\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    all_outputs = []\n",
        "    for inputs, labels in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        all_outputs.append(outputs.detach())\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs, dim=0)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on the test dataset: {100 * correct / total:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ1o6jLxUTcY",
        "outputId": "87847064-cb49-4e43-b4d5-756a1ce2cf5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/77], Loss: 0.1276\n",
            "Epoch [2/77], Loss: 0.1242\n",
            "Epoch [3/77], Loss: 0.1229\n",
            "Epoch [4/77], Loss: 0.1204\n",
            "Epoch [5/77], Loss: 0.1196\n",
            "Epoch [6/77], Loss: 0.1162\n",
            "Epoch [7/77], Loss: 0.1156\n",
            "Epoch [8/77], Loss: 0.1135\n",
            "Epoch [9/77], Loss: 0.1105\n",
            "Epoch [10/77], Loss: 0.1109\n",
            "Epoch [11/77], Loss: 0.1058\n",
            "Epoch [12/77], Loss: 0.1082\n",
            "Epoch [13/77], Loss: 0.1035\n",
            "Epoch [14/77], Loss: 0.1033\n",
            "Epoch [15/77], Loss: 0.1016\n",
            "Epoch [16/77], Loss: 0.0984\n",
            "Epoch [17/77], Loss: 0.0976\n",
            "Epoch [18/77], Loss: 0.0965\n",
            "Epoch [19/77], Loss: 0.0975\n",
            "Epoch [20/77], Loss: 0.0925\n",
            "Epoch [21/77], Loss: 0.0898\n",
            "Epoch [22/77], Loss: 0.0923\n",
            "Epoch [23/77], Loss: 0.0864\n",
            "Epoch [24/77], Loss: 0.0896\n",
            "Epoch [25/77], Loss: 0.0860\n",
            "Epoch [26/77], Loss: 0.0853\n",
            "Epoch [27/77], Loss: 0.0823\n",
            "Epoch [28/77], Loss: 0.0817\n",
            "Epoch [29/77], Loss: 0.0847\n",
            "Epoch [30/77], Loss: 0.0811\n",
            "Epoch [31/77], Loss: 0.0792\n",
            "Epoch [32/77], Loss: 0.0779\n",
            "Epoch [33/77], Loss: 0.0761\n",
            "Epoch [34/77], Loss: 0.0789\n",
            "Epoch [35/77], Loss: 0.0758\n",
            "Epoch [36/77], Loss: 0.0794\n",
            "Epoch [37/77], Loss: 0.0719\n",
            "Epoch [38/77], Loss: 0.0731\n",
            "Epoch [39/77], Loss: 0.0748\n",
            "Epoch [40/77], Loss: 0.0706\n",
            "Epoch [41/77], Loss: 0.0673\n",
            "Epoch [42/77], Loss: 0.0698\n",
            "Epoch [43/77], Loss: 0.0688\n",
            "Epoch [44/77], Loss: 0.0691\n",
            "Epoch [45/77], Loss: 0.0655\n",
            "Epoch [46/77], Loss: 0.0645\n",
            "Epoch [47/77], Loss: 0.0645\n",
            "Epoch [48/77], Loss: 0.0642\n",
            "Epoch [49/77], Loss: 0.0619\n",
            "Epoch [50/77], Loss: 0.0631\n",
            "Epoch [51/77], Loss: 0.0624\n",
            "Epoch [52/77], Loss: 0.0583\n",
            "Epoch [53/77], Loss: 0.0659\n",
            "Epoch [54/77], Loss: 0.0595\n",
            "Epoch [55/77], Loss: 0.0591\n",
            "Epoch [56/77], Loss: 0.0567\n",
            "Epoch [57/77], Loss: 0.0602\n",
            "Epoch [58/77], Loss: 0.0616\n",
            "Epoch [59/77], Loss: 0.0590\n",
            "Epoch [60/77], Loss: 0.0624\n",
            "Epoch [61/77], Loss: 0.0579\n",
            "Epoch [62/77], Loss: 0.0546\n",
            "Epoch [63/77], Loss: 0.0584\n",
            "Epoch [64/77], Loss: 0.0514\n",
            "Epoch [65/77], Loss: 0.0553\n",
            "Epoch [66/77], Loss: 0.0563\n",
            "Epoch [67/77], Loss: 0.0503\n",
            "Epoch [68/77], Loss: 0.0600\n",
            "Epoch [69/77], Loss: 0.0545\n",
            "Epoch [70/77], Loss: 0.0538\n",
            "Epoch [71/77], Loss: 0.0544\n",
            "Epoch [72/77], Loss: 0.0484\n",
            "Epoch [73/77], Loss: 0.0557\n",
            "Epoch [74/77], Loss: 0.0502\n",
            "Epoch [75/77], Loss: 0.0478\n",
            "Epoch [76/77], Loss: 0.0506\n",
            "Epoch [77/77], Loss: 0.0473\n",
            "Accuracy on the test dataset: 90.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FZU01c99UcfV"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}